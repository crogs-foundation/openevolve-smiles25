{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4996b8b2",
   "metadata": {},
   "source": [
    "# Zero-Shot Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3e63ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "from g4f.client import Client\n",
    "import re\n",
    "import time\n",
    "from pathlib import Path\n",
    "import trimesh\n",
    "import contextlib\n",
    "import tempfile\n",
    "import pandas as pd\n",
    "import cadquery as cq\n",
    "from typing import Callable, Optional\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import ot\n",
    "from scipy.spatial import KDTree\n",
    "import os\n",
    "\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e78f82",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5700005f",
   "metadata": {},
   "source": [
    "### LLM Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6ae3db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def request(model: str, prompt: str, **kwargs) -> str:\n",
    "    client = Client()\n",
    "\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt, \"additional_data\": []}]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        stream=False,\n",
    "        # provider=g4f.Provider.Yqcloud,\n",
    "        verbose=False,\n",
    "        silent=True,\n",
    "        web_search=False,\n",
    "        seed=420,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af26f94f",
   "metadata": {},
   "source": [
    "### Code extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "795a0d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_python_code(text: str):\n",
    "    pattern = r\"```python\\n(.*?)\\n```\"\n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "    if len(matches) == 0:\n",
    "        return text\n",
    "\n",
    "    return matches[0].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb166fe",
   "metadata": {},
   "source": [
    "### CadQuery Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "219a71f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_cadquery_code(code: str) -> cq.Workplane:\n",
    "    safe_globals = {\"cq\": cq}\n",
    "\n",
    "    output = StringIO()\n",
    "\n",
    "    with contextlib.redirect_stdout(output):\n",
    "        exec(code, safe_globals)\n",
    "\n",
    "        if \"r\" in safe_globals and isinstance(safe_globals[\"r\"], cq.Workplane):\n",
    "            return safe_globals[\"r\"]\n",
    "\n",
    "    raise RuntimeError(\"No valid CadQuery object named 'r' found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855c714b",
   "metadata": {},
   "source": [
    "### CadQuery to Mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c86ff699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cq_to_trimesh(workplane: cq.Workplane) -> trimesh.Trimesh:\n",
    "    \"\"\"\n",
    "    Converts a CadQuery Workplane object into a trimesh.Trimesh object.\n",
    "    \"\"\"\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".stl\", delete=False) as temp_file:\n",
    "        workplane.export(temp_file.name)\n",
    "        mesh = trimesh.load_mesh(temp_file.name)\n",
    "    return mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5481f4f4",
   "metadata": {},
   "source": [
    "### Compute Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "594f0d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_wrapper(error_value: float = 0.0, precision: int = 5, debug: bool = False):\n",
    "    \"\"\"Decorator to handle exceptions, round results, and provide a default error value.\"\"\"\n",
    "\n",
    "    def decorator(func: Callable) -> Callable:\n",
    "        def wrapper(*args, **kwargs):\n",
    "            try:\n",
    "                result = func(*args, **kwargs)\n",
    "                return round(float(result), precision)\n",
    "            except Exception as e:\n",
    "                if debug:\n",
    "                    raise\n",
    "                print(f\"Error in {func.__name__}: {e}\")\n",
    "                return error_value\n",
    "\n",
    "        return wrapper\n",
    "\n",
    "    return decorator\n",
    "\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "\n",
    "def sample_surface_points(\n",
    "    obj: trimesh.Trimesh, num_samples: int, seed: int = 420\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Samples points from a mesh surface.\"\"\"\n",
    "    return trimesh.sample.sample_surface(obj, num_samples, seed=seed)[0]\n",
    "\n",
    "\n",
    "def get_vertices(obj: trimesh.Trimesh, max_points: Optional[int] = None) -> np.ndarray:\n",
    "    \"\"\"Gets (or subsamples) vertices from a mesh.\"\"\"\n",
    "    vertices = obj.vertices\n",
    "    if max_points and len(vertices) > max_points:\n",
    "        indices = np.random.choice(len(vertices), max_points, replace=False)\n",
    "        return vertices[indices]\n",
    "    return vertices\n",
    "\n",
    "\n",
    "def _get_point_distances(\n",
    "    points1: np.ndarray, points2: np.ndarray\n",
    ") -> tuple[float, float]:\n",
    "    \"\"\"Helper to compute Chamfer and Hausdorff distances between point clouds.\"\"\"\n",
    "    tree1, tree2 = KDTree(points1), KDTree(points2)\n",
    "    dist1, _ = tree1.query(points2, k=1)\n",
    "    dist2, _ = tree2.query(points1, k=1)\n",
    "    chamfer_dist = np.mean(np.square(dist1)) + np.mean(np.square(dist2))\n",
    "    hausdorff_dist = max(np.max(dist1), np.max(dist2))\n",
    "    return chamfer_dist, hausdorff_dist\n",
    "\n",
    "\n",
    "def _scalar_similarity(val1: float, val2: float) -> float:\n",
    "    \"\"\"Helper to compute similarity between two scalar values.\"\"\"\n",
    "    maximum = max(val1, val2)\n",
    "    return 1.0 - abs(val1 - val2) / maximum if maximum > 0 else 1.0\n",
    "\n",
    "\n",
    "# --- Metric Functions ---\n",
    "\n",
    "\n",
    "@eval_wrapper()\n",
    "def iou(obj1: trimesh.Trimesh, obj2: trimesh.Trimesh) -> float:\n",
    "    intersection = obj1.intersection(obj2, check_volume=False).volume\n",
    "    union = obj1.union(obj2, check_volume=False).volume\n",
    "    return intersection / union if union > 0 else 0.0\n",
    "\n",
    "\n",
    "@eval_wrapper()\n",
    "def voxel_iou(\n",
    "    obj1: trimesh.Trimesh, obj2: trimesh.Trimesh, resolution: int = 64\n",
    ") -> float:\n",
    "    v1 = obj1.voxelized(pitch=obj1.scale / resolution).matrix\n",
    "    v2 = obj2.voxelized(pitch=obj2.scale / resolution).matrix\n",
    "\n",
    "    shape1, shape2 = np.array(v1.shape), np.array(v2.shape)\n",
    "    max_shape = np.maximum(shape1, shape2)\n",
    "\n",
    "    v1_padded = np.zeros(max_shape, dtype=bool)\n",
    "    v1_padded[tuple(map(slice, shape1))] = v1\n",
    "\n",
    "    v2_padded = np.zeros(max_shape, dtype=bool)\n",
    "    v2_padded[tuple(map(slice, shape2))] = v2\n",
    "\n",
    "    intersection = np.logical_and(v1_padded, v2_padded).sum()\n",
    "    union = np.logical_or(v1_padded, v2_padded).sum()\n",
    "    return intersection / union if union > 0 else 0.0\n",
    "\n",
    "\n",
    "@eval_wrapper()\n",
    "def inverse_chamfer_distance(\n",
    "    obj1: trimesh.Trimesh, obj2: trimesh.Trimesh, num_samples: int = 5000\n",
    ") -> float:\n",
    "    points1 = sample_surface_points(obj1, num_samples)\n",
    "    points2 = sample_surface_points(obj2, num_samples)\n",
    "    chamfer, _ = _get_point_distances(points1, points2)\n",
    "    return 1.0 - chamfer\n",
    "\n",
    "\n",
    "@eval_wrapper()\n",
    "def inverse_chamfer_distance_vertices(\n",
    "    obj1: trimesh.Trimesh, obj2: trimesh.Trimesh, max_points: int = 5000\n",
    ") -> float:\n",
    "    points1 = get_vertices(obj1, max_points)\n",
    "    points2 = get_vertices(obj2, max_points)\n",
    "    chamfer, _ = _get_point_distances(points1, points2)\n",
    "    return 1.0 - chamfer\n",
    "\n",
    "\n",
    "@eval_wrapper()\n",
    "def inverse_hausdorff_distance(\n",
    "    obj1: trimesh.Trimesh, obj2: trimesh.Trimesh, num_samples: int = 5000\n",
    ") -> float:\n",
    "    points1 = sample_surface_points(obj1, num_samples)\n",
    "    points2 = sample_surface_points(obj2, num_samples)\n",
    "    _, hausdorff = _get_point_distances(points1, points2)\n",
    "    return 1.0 - hausdorff\n",
    "\n",
    "\n",
    "@eval_wrapper()\n",
    "def inverse_hausdorff_distance_vertices(\n",
    "    obj1: trimesh.Trimesh, obj2: trimesh.Trimesh, max_points: int = 5000\n",
    ") -> float:\n",
    "    points1 = get_vertices(obj1, max_points)\n",
    "    points2 = get_vertices(obj2, max_points)\n",
    "    _, hausdorff = _get_point_distances(points1, points2)\n",
    "    return 1.0 - hausdorff\n",
    "\n",
    "\n",
    "@eval_wrapper()\n",
    "def inverse_wasserstein_distance(\n",
    "    obj1: trimesh.Trimesh, obj2: trimesh.Trimesh, num_samples: int = 1000\n",
    ") -> float:\n",
    "    points1 = sample_surface_points(obj1, num_samples)\n",
    "    points2 = sample_surface_points(obj2, num_samples)\n",
    "    a = b = np.ones((num_samples,)) / num_samples\n",
    "    cost_matrix = ot.dist(points1, points2, metric=\"sqeuclidean\")\n",
    "    emd2 = ot.emd2(a, b, cost_matrix)\n",
    "    return 1.0 - emd2  # type: ignore\n",
    "\n",
    "\n",
    "@eval_wrapper()\n",
    "def volume_similarity(obj1: trimesh.Trimesh, obj2: trimesh.Trimesh) -> float:\n",
    "    if not obj1.is_watertight or not obj2.is_watertight:\n",
    "        return 0.0\n",
    "    return _scalar_similarity(obj1.volume, obj2.volume)\n",
    "\n",
    "\n",
    "@eval_wrapper()\n",
    "def area_similarity(obj1: trimesh.Trimesh, obj2: trimesh.Trimesh) -> float:\n",
    "    return _scalar_similarity(obj1.area, obj2.area)\n",
    "\n",
    "\n",
    "@eval_wrapper()\n",
    "def inverse_centroid_distance(obj1: trimesh.Trimesh, obj2: trimesh.Trimesh) -> float:\n",
    "    distance = np.linalg.norm(obj1.centroid - obj2.centroid)\n",
    "    return float(1.0 - distance)\n",
    "\n",
    "\n",
    "@eval_wrapper()\n",
    "def inertia_similarity(obj1: trimesh.Trimesh, obj2: trimesh.Trimesh) -> float:\n",
    "    i1, i2 = obj1.moment_inertia, obj2.moment_inertia\n",
    "    norm = np.linalg.norm(i1) + np.linalg.norm(i2)\n",
    "    if norm == 0:\n",
    "        return 1.0\n",
    "    return float(1.0 - np.linalg.norm(i1 - i2) / norm)\n",
    "\n",
    "\n",
    "METRICS_DICT: dict[str, Callable] = {\n",
    "    \"iou\": iou,\n",
    "    \"viou\": voxel_iou,\n",
    "    \"cd\": inverse_chamfer_distance,\n",
    "    # \"cdv\": inverse_chamfer_distance_vertices,\n",
    "    \"hd\": inverse_hausdorff_distance,\n",
    "    # \"hdv\": inverse_hausdorff_distance_vertices,\n",
    "    \"wd\": inverse_wasserstein_distance,\n",
    "    # \"vs\": volume_similarity,\n",
    "    \"as\": area_similarity,\n",
    "    # \"ctd\": inverse_centroid_distance,\n",
    "    \"is\": inertia_similarity,\n",
    "}\n",
    "\n",
    "\n",
    "ORIENT_METRICS_DICT: dict[str, Callable] = {\n",
    "    # \"osi\": orientation_similarity_pca_invariant,\n",
    "    # \"osf\": orientation_similarity_faces,\n",
    "    # \"osv\": orientation_similarity_vertices,\n",
    "}\n",
    "\n",
    "\n",
    "def center_mesh(mesh: trimesh.Trimesh) -> trimesh.Trimesh:\n",
    "    # Get the centroid of the mesh\n",
    "    centroid = mesh.centroid\n",
    "\n",
    "    # Create a translation matrix\n",
    "    T = np.eye(4)\n",
    "    T[:3, 3] = -centroid  # translate by negative centroid\n",
    "\n",
    "    # Apply transformation\n",
    "    centered = mesh.copy()\n",
    "    centered.apply_transform(T)\n",
    "    return centered\n",
    "\n",
    "\n",
    "def transform(obj: trimesh.Trimesh) -> trimesh.Trimesh:\n",
    "    \"\"\"Normalizes a mesh to be centered and fit within a unit cube.\"\"\"\n",
    "    center = obj.bounds.mean(axis=0)\n",
    "    obj.apply_translation(-center)\n",
    "    scale = obj.extents.max()\n",
    "    if scale > 1e-7:\n",
    "        # if scale > 1:\n",
    "        obj.apply_scale(1.0 / scale)\n",
    "    return center_mesh(obj)\n",
    "\n",
    "\n",
    "def tri_to_o(trimesh_mesh: trimesh.Trimesh) -> o3d.geometry.TriangleMesh:\n",
    "    vertices = np.asarray(trimesh_mesh.vertices)\n",
    "    triangles = np.asarray(trimesh_mesh.faces)\n",
    "\n",
    "    o3d_mesh = o3d.geometry.TriangleMesh()\n",
    "    o3d_mesh.vertices = o3d.utility.Vector3dVector(vertices)\n",
    "    o3d_mesh.triangles = o3d.utility.Vector3iVector(triangles)\n",
    "\n",
    "    return o3d_mesh\n",
    "\n",
    "\n",
    "def o_to_tri(o3d_mesh):\n",
    "    vertices = np.asarray(o3d_mesh.vertices)\n",
    "    faces = np.asarray(o3d_mesh.triangles)\n",
    "\n",
    "    return trimesh.Trimesh(vertices=vertices, faces=faces)\n",
    "\n",
    "\n",
    "def preprocess_point_cloud(pcd, voxel_size):\n",
    "    pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "\n",
    "    radius_normal = voxel_size * 2\n",
    "    pcd_down.estimate_normals(\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30)\n",
    "    )\n",
    "\n",
    "    radius_feature = voxel_size * 5\n",
    "    pcd_fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "        pcd_down,\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=100),\n",
    "    )\n",
    "    return pcd_down, pcd_fpfh\n",
    "\n",
    "\n",
    "def execute_global_registration(\n",
    "    source_down, target_down, source_fpfh, target_fpfh, voxel_size\n",
    "):\n",
    "    distance_threshold = voxel_size * 1.5\n",
    "    result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "        source_down,\n",
    "        target_down,\n",
    "        source_fpfh,\n",
    "        target_fpfh,\n",
    "        True,\n",
    "        distance_threshold,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint(False),\n",
    "        3,\n",
    "        [\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(0.9),\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(\n",
    "                distance_threshold\n",
    "            ),\n",
    "        ],\n",
    "        o3d.pipelines.registration.RANSACConvergenceCriteria(100000, 0.999),\n",
    "    )\n",
    "    return result\n",
    "\n",
    "\n",
    "def align_rot(\n",
    "    source_mesh: trimesh.Trimesh,\n",
    "    target_mesh: trimesh.Trimesh,\n",
    "    n_points: int = 10000,\n",
    "    voxel_size: float = 0.05,\n",
    ") -> trimesh.Trimesh:\n",
    "    # Convert to Open3D triangle meshes and sample point clouds\n",
    "    target_pcd = tri_to_o(target_mesh).sample_points_uniformly(n_points)\n",
    "    source_pcd = tri_to_o(source_mesh).sample_points_uniformly(n_points)\n",
    "    # Preprocess point clouds\n",
    "    source_down, source_fpfh = preprocess_point_cloud(source_pcd, voxel_size)\n",
    "    target_down, target_fpfh = preprocess_point_cloud(target_pcd, voxel_size)\n",
    "\n",
    "    # Register point clouds\n",
    "    result_ransac = execute_global_registration(\n",
    "        source_down, target_down, source_fpfh, target_fpfh, voxel_size\n",
    "    )\n",
    "\n",
    "    # Transform original Open3D mesh and convert back to trimesh\n",
    "    source_o3d = tri_to_o(source_mesh)\n",
    "    source_o3d.transform(result_ransac.transformation)\n",
    "\n",
    "    return o_to_tri(source_o3d)\n",
    "\n",
    "\n",
    "def evaluate(\n",
    "    target_obj: trimesh.Trimesh, predicted_obj: trimesh.Trimesh, align: bool = True\n",
    ") -> dict[str, float]:\n",
    "    \"\"\"Computes all metrics for two (normalized) meshes.\"\"\"\n",
    "    target_obj = transform(target_obj.copy())\n",
    "\n",
    "    predicted_obj = transform(predicted_obj.copy())\n",
    "    aligned_obj = predicted_obj.copy()\n",
    "\n",
    "    if align:\n",
    "        aligned_obj = transform(align_rot(aligned_obj, target_obj))\n",
    "\n",
    "    return {\n",
    "        **{\n",
    "            name: metric_fn(target_obj, aligned_obj)\n",
    "            for name, metric_fn in METRICS_DICT.items()\n",
    "        },\n",
    "        **{\n",
    "            name: metric_fn(target_obj, predicted_obj)\n",
    "            for name, metric_fn in ORIENT_METRICS_DICT.items()\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ee1750",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcac8669",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mesh_comparison_scene(\n",
    "    meshes: list[Optional[trimesh.Trimesh]],\n",
    "    colors: Optional[list[Optional[np.ndarray]]] = None,\n",
    "    align: Optional[bool] = False,\n",
    "):\n",
    "    scene = trimesh.Scene()\n",
    "    valid_meshes = []\n",
    "    valid_colors = []\n",
    "\n",
    "    # Filter out None or empty/broken meshes\n",
    "    for mesh, color in zip(meshes, colors or [None] * len(meshes)):\n",
    "        if mesh is None or not isinstance(mesh, trimesh.Trimesh) or mesh.is_empty:\n",
    "            print(\"Warning: Skipping empty or invalid mesh.\")\n",
    "            continue\n",
    "        valid_meshes.append(mesh)\n",
    "        valid_colors.append(color)\n",
    "\n",
    "    if not valid_meshes:\n",
    "        raise ValueError(\"No valid meshes to display.\")\n",
    "\n",
    "    valid_meshes = [transform(m) for m in valid_meshes]\n",
    "    # Compute offset based on valid meshes only\n",
    "    offset = max(m.extents[0] for m in valid_meshes) * 1.2\n",
    "\n",
    "    # Center the baseline mesh (first one)\n",
    "    baseline = valid_meshes[0]\n",
    "\n",
    "    for idx, (mesh, color) in enumerate(zip(valid_meshes, valid_colors)):\n",
    "        mesh.visual.face_colors = None if color is None else color\n",
    "        if idx > 0 and align:\n",
    "            # mesh = align_mesh(mesh, baseline)\n",
    "            mesh = transform(align_rot(mesh, baseline))\n",
    "        scene.add_geometry(\n",
    "            mesh,\n",
    "            transform=trimesh.transformations.translation_matrix([offset * idx, 0, 0]),\n",
    "        )\n",
    "\n",
    "    return scene.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df990820",
   "metadata": {},
   "source": [
    "### Whole pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfdeb357",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_shot(\n",
    "    model: str,\n",
    "    prompt: str,\n",
    "    baseline_path: Path,\n",
    "    save_path: Optional[Path] = None,\n",
    "    plot_meshes: bool = True,\n",
    "    align_on_plot: bool = True,\n",
    "    align_on_evaluate: bool = True,\n",
    ") -> tuple[str, dict]:\n",
    "    response = request(model, prompt)\n",
    "    code = extract_python_code(response)\n",
    "\n",
    "    try:\n",
    "        workplane = execute_cadquery_code(code)\n",
    "        predicted_obj = cq_to_trimesh(workplane)\n",
    "        if save_path:\n",
    "            predicted_obj.export(save_path)\n",
    "        target_obj = trimesh.load_mesh(baseline_path)\n",
    "        metrics = evaluate(target_obj, predicted_obj, align_on_evaluate)\n",
    "\n",
    "        if plot_meshes:\n",
    "            display(\n",
    "                plot_mesh_comparison_scene(\n",
    "                    meshes=[target_obj, predicted_obj],\n",
    "                    colors=[\n",
    "                        np.array([0, 255, 0]),\n",
    "                        np.array([255, 0, 0]),\n",
    "                    ],\n",
    "                    align=align_on_plot,\n",
    "                )\n",
    "            )\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing code: {e}\")\n",
    "        return code, {}\n",
    "\n",
    "    return code, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c36f3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment_suite(\n",
    "    model: str,\n",
    "    prompt: str,\n",
    "    baseline_path: Path,\n",
    "    results_csv_path: Path,\n",
    "    num_repeats: int = 5,\n",
    "    num_retries: int = 10,\n",
    "    generated_meshes_path: Optional[Path] = None,\n",
    "    **zero_shot_kwargs,\n",
    ") -> pd.DataFrame | None:\n",
    "    METRIC_NAMES = [\"iou\", \"viou\", \"cd\", \"wd\", \"as\", \"is\"]\n",
    "    all_results = []\n",
    "\n",
    "    if generated_meshes_path:\n",
    "        os.makedirs(generated_meshes_path, exist_ok=True)\n",
    "\n",
    "    _zero_shot_plot_meshes = zero_shot_kwargs.get(\"plot_meshes\", False)\n",
    "    if \"plot_meshes\" in zero_shot_kwargs:\n",
    "        zero_shot_kwargs.pop(\"plot_meshes\")\n",
    "\n",
    "    for i in range(num_repeats):\n",
    "        print(f\"\\n--- Running Experiment {i + 1}/{num_repeats} ---\")\n",
    "\n",
    "        save_path = None\n",
    "        if generated_meshes_path:\n",
    "            save_path = generated_meshes_path / f\"{i + 1}.stl\"\n",
    "\n",
    "        # Run one experiment\n",
    "        for j in range(num_retries):\n",
    "            try:\n",
    "                code, metrics = zero_shot(\n",
    "                    model=model,\n",
    "                    prompt=prompt,\n",
    "                    baseline_path=baseline_path,\n",
    "                    save_path=save_path,\n",
    "                    **zero_shot_kwargs,\n",
    "                    # plot_meshes=False if i < (num_repeats-1) else zero_shot_plot_meshes\n",
    "                    plot_meshes=False,\n",
    "                )\n",
    "\n",
    "                if len(code) < 40:\n",
    "                    continue\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"External Error: {e}\")\n",
    "                if str(e) in [\"No .har file found\"]:\n",
    "                    continue\n",
    "                code = \"\"\n",
    "                metrics = None\n",
    "\n",
    "        if metrics:\n",
    "            combined_score = sum(metrics.get(k, 0) for k in METRIC_NAMES)\n",
    "            row_data = {\n",
    "                \"code\": code,\n",
    "                **metrics,\n",
    "                \"combined_score\": combined_score,\n",
    "            }\n",
    "        else:  # If the run failed\n",
    "            row_data = {\n",
    "                \"code\": code,\n",
    "                **{metric: 0 for metric in METRIC_NAMES},\n",
    "                \"combined_score\": 0,\n",
    "            }\n",
    "\n",
    "        all_results.append(row_data)\n",
    "        print(f\"Combined score: {row_data['combined_score']}\")\n",
    "        time.sleep(2)\n",
    "\n",
    "    if not all_results:\n",
    "        print(\"No results were generated to save.\")\n",
    "        return\n",
    "\n",
    "    df = pd.DataFrame(all_results)\n",
    "\n",
    "    column_order = [\"code\"] + METRIC_NAMES + [\"combined_score\"]\n",
    "    for col in column_order:\n",
    "        if col not in df.columns:\n",
    "            df[col] = None\n",
    "    df = df[column_order]\n",
    "\n",
    "    results_csv_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_csv(results_csv_path, index=False)\n",
    "    print(f\"\\nExperiment suite finished. Results saved to '{results_csv_path}'\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154187db",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de9e6ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(description: str) -> str:\n",
    "    return f\"\"\"\n",
    "You are an expert in parametric 3D modeling using CadQuery and Python. Your task is to write a Python code using the CadQuery library that generates a 3D model matching a reference information about the shape as closely as possible.\n",
    "\n",
    "Requirements:\n",
    "1. The code must use CadQuery primitives and operations.\n",
    "2. The code should assign final CadQuery solid object (`cq.Workplane` with 3D geometry) to a variable 'r' (like `r=...`), so that 'r' can be imported from other python file\n",
    "3. The script must be executable in a standard Python environment with CadQuery installed (no other packages).\n",
    "4. Remove all comments and descriptions from the solution code\n",
    "\n",
    "You have a text shape description with important information.\n",
    "\n",
    "Shape description:\n",
    "{description}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d3c39e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tube(\n",
    "    model: str,\n",
    "    plot_meshes: bool = True,\n",
    "    align_on_plot: bool = True,\n",
    "    align_on_evaluate: bool = True,\n",
    "    num_repeats: int = 10,\n",
    "):\n",
    "    desc = \"\"\"\n",
    "    A tall vertical cylinder (116mm diameter, 200mm height) is partially subtracted by a smaller offset cylinder (66mm diameter, 200mm height) In the center of cylinder\n",
    "    \"\"\"\n",
    "\n",
    "    _df = run_experiment_suite(\n",
    "        model,\n",
    "        get_prompt(desc),\n",
    "        Path(\"generated/tube.stl\"),\n",
    "        Path(f\"zero_shot/tube_{model}_zero_shot.csv\"),\n",
    "        generated_meshes_path=Path(f\"zero_shot/tube_{model}/\"),\n",
    "        num_repeats=num_repeats,\n",
    "        plot_meshes=plot_meshes,\n",
    "        align_on_plot=align_on_plot,\n",
    "        align_on_evaluate=align_on_evaluate,\n",
    "    )\n",
    "\n",
    "    # print(f\"Metrics:\\n{metrics}\\n\")\n",
    "    # print(f\"Generated Code:\\n\\n{code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "133c1a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gear(\n",
    "    model: str,\n",
    "    plot_meshes: bool = True,\n",
    "    align_on_plot: bool = True,\n",
    "    align_on_evaluate: bool = True,\n",
    "    num_repeats: int = 10,\n",
    "):\n",
    "    desc = \"\"\"\n",
    "    Gear wheel: inner radius of 10 mm, outer radius of 40 mm, thickness of 20 mm, 6 rectangular cogs as thick as a gear, protruding from the gear to a width of 20 mm and a height of 10 mm.\n",
    "    The cogs must be inserted into the gear by 2 mm.\n",
    "    \"\"\"\n",
    "\n",
    "    _df = run_experiment_suite(\n",
    "        model,\n",
    "        get_prompt(desc),\n",
    "        Path(\"generated/gear.stl\"),\n",
    "        Path(f\"zero_shot/gear_{model}_zero_shot.csv\"),\n",
    "        generated_meshes_path=Path(f\"zero_shot/gear_{model}/\"),\n",
    "        num_repeats=num_repeats,\n",
    "        plot_meshes=plot_meshes,\n",
    "        align_on_plot=align_on_plot,\n",
    "        align_on_evaluate=align_on_evaluate,\n",
    "    )\n",
    "\n",
    "    # print(f\"Metrics:\\n{metrics}\\n\")\n",
    "    # print(f\"Generated Code:\\n\\n{code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62b252cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_box(\n",
    "    model: str,\n",
    "    plot_meshes: bool = True,\n",
    "    align_on_plot: bool = True,\n",
    "    align_on_evaluate: bool = True,\n",
    "    num_repeats: int = 10,\n",
    "):\n",
    "    desc = \"\"\"\n",
    "    Box with length of 150mm, width of 100mm and bottom thickness 10 mm. Walls height: 40 mm.\n",
    "    Walls along length sides have thicknesses of 15 mm.\n",
    "    Walls along width have thicknesses of 30mm.\n",
    "    \"\"\"\n",
    "\n",
    "    _df = run_experiment_suite(\n",
    "        model,\n",
    "        get_prompt(desc),\n",
    "        Path(\"generated/open_box.stl\"),\n",
    "        Path(f\"zero_shot/open_box_{model}_zero_shot.csv\"),\n",
    "        generated_meshes_path=Path(f\"zero_shot/open_box_{model}/\"),\n",
    "        num_repeats=num_repeats,\n",
    "        plot_meshes=plot_meshes,\n",
    "        align_on_plot=align_on_plot,\n",
    "        align_on_evaluate=align_on_evaluate,\n",
    "    )\n",
    "\n",
    "    # print(f\"Metrics:\\n{metrics}\\n\")\n",
    "    # print(f\"Generated Code:\\n\\n{code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c457484",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ladder(\n",
    "    model: str,\n",
    "    plot_meshes: bool = True,\n",
    "    align_on_plot: bool = True,\n",
    "    align_on_evaluate: bool = True,\n",
    "    num_repeats: int = 10,\n",
    "):\n",
    "    desc = \"\"\"\n",
    "    The resulting object is a solid, monolithic block measuring 60 mm wide,\n",
    "    80 mm high, and 50 mm deep, with a two-step profile on its front face composed of 40 mm risers and 30 mm treads.\n",
    "    The block is bisected by a full-width planar cut on its right side that connects the top-back edge to the bottom-front edge, creating a new face angled at approximately 58 degrees relative to the base. All other primary planes and unspecified corners remain mutually orthogonal at 90 degrees.\n",
    "    \"\"\"\n",
    "\n",
    "    _df = run_experiment_suite(\n",
    "        model,\n",
    "        get_prompt(desc),\n",
    "        Path(\"generated/ladder.stl\"),\n",
    "        Path(f\"zero_shot/ladder_{model}_zero_shot.csv\"),\n",
    "        generated_meshes_path=Path(f\"zero_shot/ladder_{model}/\"),\n",
    "        num_repeats=num_repeats,\n",
    "        plot_meshes=plot_meshes,\n",
    "        align_on_plot=align_on_plot,\n",
    "        align_on_evaluate=align_on_evaluate,\n",
    "    )\n",
    "\n",
    "    # print(f\"Metrics:\\n{metrics}\\n\")\n",
    "    # print(f\"Generated Code:\\n\\n{code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8771f163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spheres(\n",
    "    model: str,\n",
    "    plot_meshes: bool = True,\n",
    "    align_on_plot: bool = True,\n",
    "    align_on_evaluate: bool = True,\n",
    "    num_repeats: int = 10,\n",
    "):\n",
    "    desc = \"\"\"\n",
    "    Big sphere with radius 100mm, It is modified by removing the part, corresponding to the small sphere with radius 80mm and shifted from the center of big sphere 20mm up and 70mm left.\n",
    "    Another small sphere of radius 50mm touches the bottom of big sphere from the outside\n",
    "    \"\"\"\n",
    "\n",
    "    _df = run_experiment_suite(\n",
    "        model,\n",
    "        get_prompt(desc),\n",
    "        Path(\"generated/spheres.stl\"),\n",
    "        Path(f\"zero_shot/spheres_{model}_zero_shot.csv\"),\n",
    "        generated_meshes_path=Path(f\"zero_shot/spheres_{model}/\"),\n",
    "        num_repeats=num_repeats,\n",
    "        plot_meshes=plot_meshes,\n",
    "        align_on_plot=align_on_plot,\n",
    "        align_on_evaluate=align_on_evaluate,\n",
    "    )\n",
    "\n",
    "    # print(f\"Metrics:\\n{metrics}\\n\")\n",
    "    # print(f\"Generated Code:\\n\\n{code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec1b087",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3234d2",
   "metadata": {},
   "source": [
    "### Tube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66f0162",
   "metadata": {},
   "source": [
    "#### Model: qwen-2.5-72b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e78c19c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Experiment 1/10 ---\n",
      "Combined score: 4.75883\n",
      "\n",
      "--- Running Experiment 2/10 ---\n",
      "Combined score: 5.22138\n",
      "\n",
      "--- Running Experiment 3/10 ---\n",
      "Combined score: 4.83028\n",
      "\n",
      "--- Running Experiment 4/10 ---\n",
      "Combined score: 5.25759\n",
      "\n",
      "--- Running Experiment 5/10 ---\n",
      "Combined score: 5.10607\n",
      "\n",
      "--- Running Experiment 6/10 ---\n",
      "Combined score: 4.81772\n",
      "\n",
      "--- Running Experiment 7/10 ---\n",
      "Combined score: 4.7771\n",
      "\n",
      "--- Running Experiment 8/10 ---\n",
      "Combined score: 5.20644\n",
      "\n",
      "--- Running Experiment 9/10 ---\n",
      "Combined score: 4.71948\n",
      "\n",
      "--- Running Experiment 10/10 ---\n",
      "Combined score: 4.80612\n",
      "\n",
      "Experiment suite finished. Results saved to 'zero_shot/tube_qwen-2.5-72b_zero_shot.csv'\n"
     ]
    }
   ],
   "source": [
    "tube(\"qwen-2.5-72b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ad9cb6",
   "metadata": {},
   "source": [
    "#### Model: qwen-2.5-coder-32b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cdf154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Experiment 1/10 ---\n",
      "Combined score: 5.54685\n",
      "\n",
      "--- Running Experiment 2/10 ---\n",
      "Error executing code: list index out of range\n",
      "Combined score: 0\n",
      "\n",
      "--- Running Experiment 3/10 ---\n",
      "Error executing code: list index out of range\n",
      "Combined score: 0\n",
      "\n",
      "--- Running Experiment 4/10 ---\n",
      "Combined score: 5.16559\n",
      "\n",
      "--- Running Experiment 5/10 ---\n",
      "Combined score: 5.9317\n",
      "\n",
      "--- Running Experiment 6/10 ---\n",
      "Combined score: 5.23066\n",
      "\n",
      "--- Running Experiment 7/10 ---\n",
      "Combined score: 5.61344\n",
      "\n",
      "--- Running Experiment 8/10 ---\n",
      "Error executing code: list index out of range\n",
      "Combined score: 0\n",
      "\n",
      "--- Running Experiment 9/10 ---\n",
      "Error executing code: list index out of range\n",
      "Combined score: 0\n",
      "\n",
      "--- Running Experiment 10/10 ---\n",
      "Error executing code: list index out of range\n",
      "Combined score: 0\n",
      "\n",
      "Experiment suite finished. Results saved to 'zero_shot/tube_qwen-2.5-coder-32b_zero_shot.csv'\n"
     ]
    }
   ],
   "source": [
    "tube(\"qwen-2.5-coder-32b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd23b8c3",
   "metadata": {},
   "source": [
    "#### Model: gpt-o4-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfb7ffda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Experiment 1/10 ---\n",
      "Combined score: 5.90918\n",
      "\n",
      "--- Running Experiment 2/10 ---\n",
      "Combined score: 5.766220000000001\n",
      "\n",
      "--- Running Experiment 3/10 ---\n",
      "Combined score: 5.65876\n",
      "\n",
      "--- Running Experiment 4/10 ---\n",
      "Combined score: 5.9093800000000005\n",
      "\n",
      "--- Running Experiment 5/10 ---\n",
      "Combined score: 5.24488\n",
      "\n",
      "--- Running Experiment 6/10 ---\n",
      "Combined score: 5.90128\n",
      "\n",
      "--- Running Experiment 7/10 ---\n",
      "Combined score: 5.27279\n",
      "\n",
      "--- Running Experiment 8/10 ---\n",
      "Combined score: 5.72854\n",
      "\n",
      "--- Running Experiment 9/10 ---\n",
      "Combined score: 5.94564\n",
      "\n",
      "--- Running Experiment 10/10 ---\n",
      "Combined score: 5.16979\n",
      "\n",
      "Experiment suite finished. Results saved to 'zero_shot/tube_o4-mini_zero_shot.csv'\n"
     ]
    }
   ],
   "source": [
    "tube(\"o4-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cac4722",
   "metadata": {},
   "source": [
    "### Gear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83728c2",
   "metadata": {},
   "source": [
    "#### Model: qwen-2.5-72b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b1a8eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Experiment 1/10 ---\n",
      "Error executing code: 'Vector' object has no attribute 'rotated'\n",
      "Combined score: 0\n",
      "\n",
      "--- Running Experiment 2/10 ---\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (61) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "Combined score: 4.4436\n",
      "\n",
      "--- Running Experiment 3/10 ---\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (56) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "Combined score: 4.49764\n",
      "\n",
      "--- Running Experiment 4/10 ---\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (51) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "Combined score: 4.38339\n",
      "\n",
      "--- Running Experiment 5/10 ---\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (51) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "Combined score: 4.44698\n",
      "\n",
      "--- Running Experiment 6/10 ---\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (52) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "Combined score: 4.4572199999999995\n",
      "\n",
      "--- Running Experiment 7/10 ---\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (56) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "Combined score: 4.43957\n",
      "\n",
      "--- Running Experiment 8/10 ---\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (61) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "Combined score: 4.3815\n",
      "\n",
      "--- Running Experiment 9/10 ---\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (55) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "Combined score: 4.38437\n",
      "\n",
      "--- Running Experiment 10/10 ---\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (56) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "Combined score: 4.44561\n",
      "\n",
      "Experiment suite finished. Results saved to 'zero_shot/gear_qwen-2.5-72b_zero_shot.csv'\n"
     ]
    }
   ],
   "source": [
    "gear(\"qwen-2.5-72b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc26c42",
   "metadata": {},
   "source": [
    "#### Model: qwen-2.5-coder-32b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "659c702d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Experiment 1/10 ---\n",
      "Error executing code: Can not return the Nth element of an empty list\n",
      "Combined score: 0\n",
      "\n",
      "--- Running Experiment 2/10 ---\n",
      "Error executing code: 'Workplane' object has no attribute 'gear'\n",
      "Combined score: 0\n",
      "\n",
      "--- Running Experiment 3/10 ---\n",
      "Error executing code: Can not return the Nth element of an empty list\n",
      "Combined score: 0\n",
      "\n",
      "--- Running Experiment 4/10 ---\n",
      "Error executing code: 'Workplane' object has no attribute 'gear'\n",
      "Combined score: 0\n",
      "\n",
      "--- Running Experiment 5/10 ---\n",
      "Error executing code: 'Workplane' object has no attribute 'gear'\n",
      "Combined score: 0\n",
      "\n",
      "--- Running Experiment 6/10 ---\n",
      "Error executing code: Can not return the Nth element of an empty list\n",
      "Combined score: 0\n",
      "\n",
      "--- Running Experiment 7/10 ---\n",
      "Error executing code: Can not return the Nth element of an empty list\n",
      "Combined score: 0\n",
      "\n",
      "--- Running Experiment 8/10 ---\n",
      "Error executing code: Can not return the Nth element of an empty list\n",
      "Combined score: 0\n",
      "\n",
      "--- Running Experiment 9/10 ---\n",
      "Error executing code: 'Workplane' object has no attribute 'gear'\n",
      "Combined score: 0\n",
      "\n",
      "--- Running Experiment 10/10 ---\n",
      "Error executing code: 'Workplane' object has no attribute 'gear'\n",
      "Combined score: 0\n",
      "\n",
      "Experiment suite finished. Results saved to 'zero_shot/gear_qwen-2.5-coder-32b_zero_shot.csv'\n"
     ]
    }
   ],
   "source": [
    "gear(\"qwen-2.5-coder-32b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa24da97",
   "metadata": {},
   "source": [
    "#### Model: gpt-o4-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c801d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Experiment 1/10 ---\n",
      "Combined score: 4.47665\n",
      "\n",
      "--- Running Experiment 2/10 ---\n",
      "Combined score: 4.44525\n",
      "\n",
      "--- Running Experiment 3/10 ---\n",
      "Error executing code: 'OCP.TopLoc.TopLoc_Location' object has no attribute 'getAttribute'\n",
      "Combined score: 0\n",
      "\n",
      "--- Running Experiment 4/10 ---\n",
      "Combined score: 4.212\n",
      "\n",
      "--- Running Experiment 5/10 ---\n",
      "Error executing code: Fillets requires that edges be selected\n",
      "Combined score: 0\n",
      "\n",
      "--- Running Experiment 6/10 ---\n",
      "Combined score: 3.67421\n",
      "\n",
      "--- Running Experiment 7/10 ---\n",
      "Combined score: 4.32\n",
      "\n",
      "--- Running Experiment 8/10 ---\n",
      "Combined score: 4.54431\n",
      "\n",
      "--- Running Experiment 9/10 ---\n",
      "Combined score: 4.50567\n",
      "\n",
      "--- Running Experiment 10/10 ---\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (78) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "Combined score: 4.42464\n",
      "\n",
      "Experiment suite finished. Results saved to 'zero_shot/gear_gpt-4.1-mini_zero_shot.csv'\n"
     ]
    }
   ],
   "source": [
    "# gear(\"gpt-4.1-mini\")\n",
    "gear(\"o4-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259b2945",
   "metadata": {},
   "source": [
    "### Open box"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4acb47",
   "metadata": {},
   "source": [
    "#### Model: qwen-2.5-72b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2666dd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Experiment 1/10 ---\n",
      "Combined score: 3.98437\n",
      "\n",
      "--- Running Experiment 2/10 ---\n",
      "Combined score: 4.1654800000000005\n",
      "\n",
      "--- Running Experiment 3/10 ---\n",
      "Combined score: 4.06401\n",
      "\n",
      "--- Running Experiment 4/10 ---\n",
      "Combined score: 4.17215\n",
      "\n",
      "--- Running Experiment 5/10 ---\n",
      "Combined score: 4.08194\n",
      "\n",
      "--- Running Experiment 6/10 ---\n",
      "Combined score: 4.1139600000000005\n",
      "\n",
      "--- Running Experiment 7/10 ---\n",
      "Combined score: 4.3168\n",
      "\n",
      "--- Running Experiment 8/10 ---\n",
      "Combined score: 4.19172\n",
      "\n",
      "--- Running Experiment 9/10 ---\n",
      "Combined score: 4.12845\n",
      "\n",
      "--- Running Experiment 10/10 ---\n",
      "Combined score: 4.16338\n",
      "\n",
      "Experiment suite finished. Results saved to 'zero_shot/open_box_qwen-2.5-72b_zero_shot.csv'\n"
     ]
    }
   ],
   "source": [
    "open_box(\"qwen-2.5-72b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdeebdbc",
   "metadata": {},
   "source": [
    "#### Model: qwen-2.5-coder-32b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48db96cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Experiment 1/10 ---\n",
      "Combined score: 4.23148\n",
      "\n",
      "--- Running Experiment 2/10 ---\n",
      "Combined score: 4.0703\n",
      "\n",
      "--- Running Experiment 3/10 ---\n",
      "Combined score: 4.22053\n",
      "\n",
      "--- Running Experiment 4/10 ---\n",
      "Combined score: 4.31126\n",
      "\n",
      "--- Running Experiment 5/10 ---\n",
      "Combined score: 3.185\n",
      "\n",
      "--- Running Experiment 6/10 ---\n",
      "Combined score: 2.9887799999999998\n",
      "\n",
      "--- Running Experiment 7/10 ---\n",
      "Combined score: 3.42699\n",
      "\n",
      "--- Running Experiment 8/10 ---\n",
      "Combined score: 4.24426\n",
      "\n",
      "--- Running Experiment 9/10 ---\n",
      "Combined score: 4.11606\n",
      "\n",
      "--- Running Experiment 10/10 ---\n",
      "Combined score: 3.22801\n",
      "\n",
      "Experiment suite finished. Results saved to 'zero_shot/open_box_qwen-2.5-coder-32b_zero_shot.csv'\n"
     ]
    }
   ],
   "source": [
    "open_box(\"qwen-2.5-coder-32b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b79ba65",
   "metadata": {},
   "source": [
    "#### Model: gpt-o4-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3b37d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Experiment 1/10 ---\n",
      "Combined score: 4.63408\n",
      "\n",
      "--- Running Experiment 2/10 ---\n",
      "Combined score: 4.73234\n",
      "\n",
      "--- Running Experiment 3/10 ---\n",
      "Combined score: 4.28442\n",
      "\n",
      "--- Running Experiment 4/10 ---\n",
      "Combined score: 3.45331\n",
      "\n",
      "--- Running Experiment 5/10 ---\n",
      "Combined score: 2.45934\n",
      "\n",
      "--- Running Experiment 6/10 ---\n",
      "Combined score: 3.81969\n",
      "\n",
      "--- Running Experiment 7/10 ---\n",
      "Combined score: 2.95451\n",
      "\n",
      "--- Running Experiment 8/10 ---\n",
      "Combined score: 3.13128\n",
      "\n",
      "--- Running Experiment 9/10 ---\n",
      "Combined score: 3.90321\n",
      "\n",
      "--- Running Experiment 10/10 ---\n",
      "Combined score: 4.39453\n",
      "\n",
      "Experiment suite finished. Results saved to 'zero_shot/open_box_gpt-4.1-mini_zero_shot.csv'\n"
     ]
    }
   ],
   "source": [
    "# open_box(\"gpt-4.1-mini\")\n",
    "open_box(\"o4-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e78b8a7",
   "metadata": {},
   "source": [
    "### Ladder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c03f1de",
   "metadata": {},
   "source": [
    "#### Model: qwen-2.5-72b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a00c85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Experiment 1/10 ---\n",
      "Error executing code: BRep_API: command not done\n",
      "Combined score: 0\n",
      "\n",
      "--- Running Experiment 2/10 ---\n",
      "Combined score: 3.86702\n",
      "\n",
      "--- Running Experiment 3/10 ---\n",
      "Combined score: 3.67951\n",
      "\n",
      "--- Running Experiment 4/10 ---\n",
      "Combined score: 3.75921\n",
      "\n",
      "--- Running Experiment 5/10 ---\n",
      "Combined score: 3.75036\n",
      "\n",
      "--- Running Experiment 6/10 ---\n",
      "Combined score: 3.73618\n",
      "\n",
      "--- Running Experiment 7/10 ---\n",
      "Error executing code: BRep_API: command not done\n",
      "Combined score: 0\n",
      "\n",
      "--- Running Experiment 8/10 ---\n",
      "Combined score: 3.76526\n",
      "\n",
      "--- Running Experiment 9/10 ---\n",
      "Combined score: 3.6976\n",
      "\n",
      "--- Running Experiment 10/10 ---\n",
      "Combined score: 3.68638\n",
      "\n",
      "Experiment suite finished. Results saved to 'zero_shot/ladder_qwen-2.5-72b_zero_shot.csv'\n"
     ]
    }
   ],
   "source": [
    "ladder(\"qwen-2.5-72b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9870a1",
   "metadata": {},
   "source": [
    "#### Model: qwen-2.5-coder-32b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5566c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Experiment 1/10 ---\n",
      "Combined score: 3.74189\n",
      "\n",
      "--- Running Experiment 2/10 ---\n",
      "Combined score: 3.78631\n",
      "\n",
      "--- Running Experiment 3/10 ---\n",
      "Combined score: 3.84661\n",
      "\n",
      "--- Running Experiment 4/10 ---\n",
      "Combined score: 3.8189699999999998\n",
      "\n",
      "--- Running Experiment 5/10 ---\n",
      "Combined score: 3.74382\n",
      "\n",
      "--- Running Experiment 6/10 ---\n",
      "Combined score: 4.06152\n",
      "\n",
      "--- Running Experiment 7/10 ---\n",
      "Combined score: 3.7071199999999997\n",
      "\n",
      "--- Running Experiment 8/10 ---\n",
      "Combined score: 3.7552499999999998\n",
      "\n",
      "--- Running Experiment 9/10 ---\n",
      "Combined score: 3.92842\n",
      "\n",
      "--- Running Experiment 10/10 ---\n",
      "Combined score: 3.62857\n",
      "\n",
      "Experiment suite finished. Results saved to 'zero_shot/ladder_qwen-2.5-coder-32b_zero_shot.csv'\n"
     ]
    }
   ],
   "source": [
    "ladder(\"qwen-2.5-coder-32b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ffa98b",
   "metadata": {},
   "source": [
    "#### Model: gpt-o4-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e82455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Experiment 1/10 ---\n",
      "Combined score: 3.85698\n",
      "\n",
      "--- Running Experiment 2/10 ---\n",
      "Error executing code: Cannot build face(s): wires not planar\n",
      "Combined score: 0\n",
      "\n",
      "--- Running Experiment 3/10 ---\n",
      "Combined score: 4.11967\n",
      "\n",
      "--- Running Experiment 4/10 ---\n",
      "Combined score: 3.28158\n",
      "\n",
      "--- Running Experiment 5/10 ---\n",
      "Combined score: 3.80841\n",
      "\n",
      "--- Running Experiment 6/10 ---\n",
      "Error executing code: You have to keep at least one half\n",
      "Combined score: 0\n",
      "\n",
      "--- Running Experiment 7/10 ---\n",
      "Combined score: 2.89912\n",
      "\n",
      "--- Running Experiment 8/10 ---\n",
      "Combined score: 3.76101\n",
      "\n",
      "--- Running Experiment 9/10 ---\n",
      "Combined score: 4.16301\n",
      "\n",
      "--- Running Experiment 10/10 ---\n",
      "Combined score: 4.01975\n",
      "\n",
      "Experiment suite finished. Results saved to 'zero_shot/ladder_gpt-4_zero_shot.csv'\n"
     ]
    }
   ],
   "source": [
    "# ladder(\"gpt-4\")\n",
    "ladder(\"o4-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db014af2",
   "metadata": {},
   "source": [
    "### Spheres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be283b30",
   "metadata": {},
   "source": [
    "#### Model: qwen-2.5-72b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96e2f27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Experiment 1/10 ---\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (81) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "Combined score: 3.08485\n",
      "\n",
      "--- Running Experiment 2/10 ---\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (73) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "Combined score: 3.18883\n",
      "\n",
      "--- Running Experiment 3/10 ---\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (71) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "Combined score: 3.09856\n",
      "\n",
      "--- Running Experiment 4/10 ---\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (79) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "Combined score: 3.14558\n",
      "\n",
      "--- Running Experiment 5/10 ---\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (80) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "Combined score: 3.13778\n",
      "\n",
      "--- Running Experiment 6/10 ---\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (71) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "Combined score: 3.10743\n",
      "\n",
      "--- Running Experiment 7/10 ---\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (76) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "Combined score: 3.21067\n",
      "\n",
      "--- Running Experiment 8/10 ---\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (66) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "Combined score: 3.08923\n",
      "\n",
      "--- Running Experiment 9/10 ---\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (77) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "Combined score: 3.02555\n",
      "\n",
      "--- Running Experiment 10/10 ---\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (66) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "Combined score: 3.18969\n",
      "\n",
      "Experiment suite finished. Results saved to 'zero_shot/spheres_qwen-2.5-72b_zero_shot.csv'\n"
     ]
    }
   ],
   "source": [
    "spheres(\"qwen-2.5-72b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06f96ce",
   "metadata": {},
   "source": [
    "#### Model: qwen-2.5-coder-32b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a44ef44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Experiment 1/10 ---\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (14) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "Combined score: 2.8313800000000002\n",
      "\n",
      "--- Running Experiment 2/10 ---\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (13) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "Combined score: 2.82884\n",
      "\n",
      "--- Running Experiment 3/10 ---\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (14) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "Combined score: 2.8318\n",
      "\n",
      "--- Running Experiment 4/10 ---\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (8) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "Combined score: 2.8304899999999997\n",
      "\n",
      "--- Running Experiment 5/10 ---\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (12) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "Combined score: 2.82606\n",
      "\n",
      "--- Running Experiment 6/10 ---\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (10) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "Combined score: 2.83203\n",
      "\n",
      "--- Running Experiment 7/10 ---\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (16) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "Combined score: 2.83181\n",
      "\n",
      "--- Running Experiment 8/10 ---\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (15) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "Combined score: 2.8318\n",
      "\n",
      "--- Running Experiment 9/10 ---\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (13) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "Combined score: 2.82613\n",
      "\n",
      "--- Running Experiment 10/10 ---\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (17) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "Combined score: 2.82835\n",
      "\n",
      "Experiment suite finished. Results saved to 'zero_shot/spheres_qwen-2.5-coder-32b_zero_shot.csv'\n"
     ]
    }
   ],
   "source": [
    "spheres(\"qwen-2.5-coder-32b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e36389",
   "metadata": {},
   "source": [
    "#### Model: gpt-o4-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf561ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Experiment 1/10 ---\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (73) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "Combined score: 3.10005\n",
      "\n",
      "--- Running Experiment 2/10 ---\n",
      "Error executing code: GeomAPI_ProjectPointOnSurf::LowerDistanceParameters\n",
      "Combined score: 0\n",
      "\n",
      "--- Running Experiment 3/10 ---\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (46) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "Combined score: 2.9404\n",
      "\n",
      "--- Running Experiment 4/10 ---\n",
      "Combined score: 3.86352\n",
      "\n",
      "--- Running Experiment 5/10 ---\n",
      "Combined score: 5.20708\n",
      "\n",
      "--- Running Experiment 6/10 ---\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (79) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "Combined score: 2.99611\n",
      "\n",
      "--- Running Experiment 7/10 ---\n",
      "Error executing code: GeomAPI_ProjectPointOnSurf::LowerDistanceParameters\n",
      "Combined score: 0\n",
      "\n",
      "--- Running Experiment 8/10 ---\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (50) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "Combined score: 3.11424\n",
      "\n",
      "--- Running Experiment 9/10 ---\n",
      "Error executing code: GeomAPI_ProjectPointOnSurf::LowerDistanceParameters\n",
      "Combined score: 0\n",
      "\n",
      "--- Running Experiment 10/10 ---\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (54) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "Combined score: 3.12652\n",
      "\n",
      "Experiment suite finished. Results saved to 'zero_shot/spheres_gpt-4_zero_shot.csv'\n"
     ]
    }
   ],
   "source": [
    "# spheres(\"gpt-4\")\n",
    "spheres(\"o4-mini\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openevolve",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
